---
title: "Homework 3"
author: 'sgr344: Simone Rittenhouse'
date: "11/23/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}

library(dplyr)
library(magrittr)
library(readxl)
library(tinytex)
library(haven)
library(Matching)

```

# Problem 1

## Part a

The distribution of $Y_i|X_i,D_i$ is $\mathcal{N}(X_i\beta + \tau D_i, 1)$ Its mean is $\mu = X_i \beta + \tau D_i$, and its variance is $\sigma^2 = 1$.

\begin{align*}
F_{Y_i|D_i, X_i}(y) & = Pr(Y_i|X_i, D_i \leq y) \\
& = Pr(\frac{Y_i|X_i, D_i - \mu}{\sigma^2} \leq \frac{y - \mu}{\sigma^2}) \\
& = Pr(\frac{Y_i|X_i, D_i - (X_i\beta + \tau D_i)}{1^2} \leq \frac{y - (X_i\beta + \tau D_i)}{1^2}) \\
& = Pr(\frac{Y_i|X_i, D_i - (X_i\beta + \tau D_i)}{1^2} \leq \frac{y - (X_i\beta + \tau D_i)}{1^2}) \\
& = Pr(\frac{Y_i|X_i, D_i - (X_i\beta + \tau D_i)}{1^2} \leq y - (X_i\beta + \tau D_i)) \\
& = \Phi (y - (X_i \beta + \tau D_i))
\end{align*}


The PDF is $\phi (y - (X_i \beta + \tau D_i))$

The CDF is $\Phi (y - (X_i \beta + \tau D_i))$

## Part b

\begin{align*}
E[D_i|X_i = 1] & = Pr(D_i = 1|X_i = 1) \\
& = Pr(X_i \gamma + \nu_i > 0) \\
& = Pr((1)\gamma + \nu_i > 0)
\end{align*}

Because $\nu_i$ is a standard normal random variable, $\nu_i + \gamma$ ~ $\mathcal{N}(\gamma, 1)$

\begin{align*}
& = 1 - Pr(\gamma + \nu_i \leq 0) \\
& = 1 - Pr(\frac{(\gamma + \nu_i) - \gamma}{1^2} \leq \frac{0 - \gamma}{1^2}) && \text{(standardizing)}\\
& = 1 - Pr(\frac{(\gamma + \nu_i) - \gamma}{1^2} \leq -\gamma)\\
& = 1 - \Phi (-\gamma) \\
& = \Phi (\gamma)
\end{align*}

Therefore, $E[D_i|X_i = 1] = \Phi (\gamma)$

\begin{align*}
E[D_i|X_i = 0] & = Pr(D_i = 1|X_i = 0) \\
& = Pr(X_i \gamma + \nu_i > 0) \\
& = Pr((0)\gamma + \nu_i > 0) \\
& = Pr(\nu_i > 0) \\
& = 1 - Pr(\nu_i \leq 0) \\
& = 1 - Pr(\frac{\nu_i - 0}{1^2} \leq \frac{0 - 0}{1^2}) && \text{(standardizing)}\\
& = 1 - Pr(\nu_i \leq 0)\\
& = 1 - \Phi (0) \\
& = 1 - \frac{1}{2} \\
& = \frac{1}{2}
\end{align*}

Therefore, $E[D_i|X_i = 0] = \frac{1}{2}$

## Part c

\begin{align*}
Pr(X_i = 1|D_i = 1) &= \frac{Pr(D_i = 1|X_i = 1)Pr(X_i=1)}{Pr(D_i=1|X_i=1)Pr(X_i=1) + Pr(D_i=1|X_i=0)Pr(X_i=0)} \\
& = \frac{\Phi (\gamma) \pi}{\Phi (\gamma) \pi + \frac{1}{2}(1-\pi)} \\
\end{align*}

Therefore, $Pr(X_i = 1|D_i =1) = \frac{\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)}$

\begin{align*}
Pr(X_i = 1|D_i = 1) &= \frac{Pr(D_i = 0|X_i = 1)Pr(X_i=1)}{Pr(D_i=0|X_i=1)Pr(X_i=1) + Pr(D_i=0|X_i=0)Pr(X_i=0)} \\
& = \frac{(1 - \Phi (\gamma)) \pi}{(1- \Phi (\gamma)) \pi + (1-\frac{1}{2})(1-\pi)} \\
& = \frac{\Phi (-\gamma) \pi}{\Phi (-\gamma) \pi + \frac{1}{2}(1-\pi)} \\
\end{align*}

Therefore, $Pr(X_i = 1|D_i=0) = \frac{\Phi(-\gamma)\pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1-\pi)}$

## Part d

Find $\eta - \tau$:

\begin{align*}
\eta & = E[Y_i|D_i=1] - E[Y_i|D_i=0] \\
\eta - \tau & = E[Y_i|D_i=1] - E[Y_i|D_i=0] - \tau \\
& = E[E[Y_i|D_i=1, X_i=x]] - E[E[Y_i|D_i=0, X_i=x]] - \tau
\end{align*}

\begin{align*}
E[E[Y_i|D_i=1, X_i=x]] & = E[Y_i|D_i=1, X_i=1]Pr(X_i=1|D_i=1) + E[Y_i|D_i=1, X_i=0]Pr(X_i=0|D_i=1) \\
& = E[Y_i|D_i=1, X_i=1]Pr(X_i=1|D_i=1) + E[Y_i|D_i=1, X_i=0](1 - Pr(X_i=1|D_i=1)) \\
& = ((1)\beta + (1)\tau)(\frac{\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)}) + ((0)\beta + (1)\tau)(1 - \frac{\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)}) \\
& = (\beta + \tau)(\frac{\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)}) + \tau(1 - \frac{\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)}) \\
& = \frac{(\beta + \tau)\Phi(\gamma) \pi}{\Phi(\gamma)\pi + \frac{1}{2}(1-\pi)} + \tau(1 - \frac{\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)})
\end{align*}

\begin{align*}
E[E[Y_i|D_i=0, X_i=x]] & = E[Y_i|D_i=0, X_i=1]Pr(X_i=1|D_i=0) + E[Y_i|D_i=0, X_i=0]Pr(X_i=0|D_i=0) \\
& = ((1)\beta + (0)\tau)(\frac{\Phi(-\gamma) \pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1 -\pi)}) + ((0)\beta + (0)\tau)Pr(X_i=0|D_i=0) \\
& = \beta(\frac{\Phi(-\gamma) \pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1 -\pi)}) + 0 \\
& = \frac{\beta \Phi(-\gamma) \pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1 -\pi)}
\end{align*}

Therefore:

\begin{align*}
\eta - \tau & = \frac{(\beta + \tau)\Phi(\gamma) \pi}{\Phi(\gamma)\pi + \frac{1}{2}(1-\pi)} + \tau(1 - \frac{\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)}) - \frac{\beta \Phi(-\gamma) \pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1 -\pi)} - \tau \\
& = \frac{\beta\Phi(\gamma) \pi}{\Phi(\gamma)\pi + \frac{1}{2}(1-\pi)} + \frac{\tau\Phi(\gamma) \pi}{\Phi(\gamma)\pi + \frac{1}{2}(1-\pi)} + \tau - \frac{\tau\Phi(\gamma) \pi}{\Phi(\gamma) \pi + \frac{1}{2}(1 -\pi)}) - \frac{\beta \Phi(-\gamma) \pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1 -\pi)} - \tau \\
& = \frac{\beta\Phi(\gamma) \pi}{\Phi(\gamma)\pi + \frac{1}{2}(1-\pi)} - \frac{\beta \Phi(-\gamma) \pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1 -\pi)} \\
& = \beta(\frac{\Phi(\gamma) \pi}{\Phi(\gamma)\pi + \frac{1}{2}(1-\pi)} - \frac{\Phi(-\gamma) \pi}{\Phi(-\gamma) \pi + \frac{1}{2}(1 -\pi)}) \\
\end{align*}

# Problem 2

## Part a

\begin{align*}
\gamma_1 & = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{D} \\
& = \frac{1}{\sum_{i=1}^{n}X_i} \sum_{i=1}^{n}X_i D_i
\end{align*}

Because in this model X = 1,

$\hat{e}(1) = \frac{1}{N_{X_i=1}} N_{X_i=1, D_i=1} = \frac{N_{X_i=1, D_i=1}}{N_{X_i=1}}$

\begin{align*}
\gamma_0 & = ((1 - \mathbf{X})^\top (1-\mathbf{X})^{-1} (1-\mathbf{X})^\top \mathbf{D} \\
& = \frac{1}{\sum_{i=1}^{n}(1-X_i)} \sum_{i=1}^{n}(1-X_i) D_i
\end{align*}

Because in this model X = 0,

$\hat{e}(0) = \frac{1}{N_{X_i=0}} N_{X_i=0, D_i=1} = \frac{N_{X_i=0, D_i=1}}{N_{X_i=0}}$

## Part b

\begin{align*}
\frac{1}{n} \sum_{i=1}^{n} \frac{Y_i D_i}{\hat{e}(X_i)} - \frac{Y_i(1-D_i)}{(1-\hat{e}(X_i))} & =
\frac{1}{n} (\sum_{i=1}^{n} \frac{Y_i D_i}{\hat{e}(X_i)} - \sum_{i=1}^{n}\frac{Y_i(1-D_i)}{(1-\hat{e}(X_i))}) \\
& = \frac{1}{n} (\sum_{i:X_i=0}^{n} \frac{Y_i D_i}{\hat{e}(0)} - \sum_{i:X_i=0}^{n}\frac{Y_i(1-D_i)}{(1-\hat{e}(0))} + \sum_{i:X_i=1}^{n} \frac{Y_i D_i}{\hat{e}(1)} - \sum_{i:X_i=1}^{n}\frac{Y_i(1-D_i)}{(1-\hat{e}(1))}) \\
& = \frac{1}{n} (\sum_{i:X_i=0}^{n} \frac{Y_i D_i}{\frac{N_{X_i=0, D_i=1}}{N_{X_i=0}}} - \sum_{i:X_i=0}^{n}\frac{Y_i(1-D_i)}{(1-\frac{N_{X_i=0, D_i=1}}{N_{X_i=0}})} + \sum_{i:X_i=1}^{n} \frac{Y_i D_i}{\frac{N_{X_i=1, D_i=1}}{N_{X_i=1}}} - \sum_{i:X_i=1}^{n}\frac{Y_i(1-D_i)}{(1-\frac{N_{X_i=1, D_i=1}}{N_{X_i=1}})}) \\
\end{align*}

Because $D_i$ is binary (an indicator function), $1-\hat{e}(x) = 1 - Pr(D_i=1|X_i=x) = Pr(D_i=0|X_i=x)$
Therefore:

\begin{align*}
& = \frac{1}{n} (\sum_{i:X_i=0}^{n} \frac{Y_i D_i}{\frac{N_{X_i=0, D_i=1}}{N_{X_i=0}}} - \sum_{i:X_i=0}^{n}\frac{Y_i(1-D_i)}{\frac{N_{X_i=0, D_i=0}}{N_{X_i=0}}} + \sum_{i:X_i=1}^{n} \frac{Y_i D_i}{\frac{N_{X_i=1, D_i=1}}{N_{X_i=1}}} - \sum_{i:X_i=1}^{n}\frac{Y_i(1-D_i)}{\frac{N_{X_i=1, D_i=0}}{N_{X_i=1}})}) \\
& = \frac{1}{n} (\sum_{i:X_i=0}^{n} N_{X_i=0}\frac{Y_i D_i}{N_{X_i=0, D_i=1}} - \sum_{i:X_i=0}^{n}N_{X_i=0}\frac{Y_i(1-D_i)}{N_{X_i=0, D_i=0}} + \sum_{i:X_i=1}^{n} N_{X_i=1}\frac{Y_i D_i}{N_{X_i=1, D_i=1}} - \sum_{i:X_i=1}^{n}N_{X_i=1}\frac{Y_i(1-D_i)}{N_{X_i=1, D_i=0}}) \\
& = \sum_{x=0}^{1}\frac{1}{n} (\sum_{i:X_i=x} N_{X_i=x}\frac{Y_i D_i}{N_{X_i=x, D_i=1}} - \sum_{i:X_i=x}N_{X_i=x}\frac{Y_i(1-D_i)}{N_{X_i=x, D_i=0}})\\
& = \sum_{x=0}^{1}\frac{N_{X=x}}{n} (\sum_{i:X_i=x}\frac{Y_i D_i}{N_{X_i=x, D_i=1}} - \sum_{i:X_i=x} \frac{Y_i(1-D_i)}{N_{X_i=x, D_i=0}})\\
& = \sum_{x=0}^{1}\frac{N_{X=x}}{n} (\frac{1}{N_{X_i=x, D_i=1}}\sum_{i:X_i=x}Y_i D_i - \frac{1}{N_{X_i=x, D_i=0}}\sum_{i:X_i=x} Y_i(1-D_i))
\end{align*}

## Part c (Bonus)

Yes, the estimates of our propensity scores obtained through linear regression will be biased because in the true model, the probability of $D_i = 1$ given $X_i$ was dependent not only on $X_i$ but on the normally distributed term $\nu_i$. However, linear regression assigns the probability of $D_i=1$ through a linear model that doesn't contain $\nu_i$ - meaning that the probability of $D_i=1$ using the linear model will not be exactly the same as the true propensity of treatment.

# Problem 3

```{r, echo=TRUE}

#loading the data set
trc <- read_dta("/Users/simonerittenhouse/Desktop/Causal Inference/trc_data.dta")

```

## Part a

```{r, echo=TRUE}

ATE_hat <- mean(trc$RUSTAND[trc$TRCKNOW == 1]) - mean(trc$RUSTAND[trc$TRCKNOW == 0])

var_ate_hat <- var(trc$RUSTAND[trc$TRCKNOW == 1])/
               sum(trc$TRCKNOW == 1) +
               var(trc$RUSTAND[trc$TRCKNOW == 0])/
               sum(trc$TRCKNOW == 0)

ATE_hat
var_ate_hat

SE <- sqrt(var_ate_hat)
SE

CI_95 <- c(ATE_hat - qnorm(.975)*SE, ATE_hat + qnorm(.975)*SE)
CI_95


```
Our estimated average treatment effect is -0.2177317 with a variance of 0.001965248. A confidence interval around this estimate is [-0.3046191, -0.1308444]. Because this interval does not contain 0, we can reject the null hypothesis and conclude that exposure to the TRC had a significant negative effect on racial attitudes. This means that significantly fewer respondents reported that it's difficult to understand the customs and ways of the opposite racial group after being exposed to the TRC.

## Part b

```{r, echo = TRUE}

# standardizing covariates
trc <- trc %>% mutate(age_std = age/sd(age), 
                      female_std = female/sd(female),
                      wealth_std = wealth/sd(wealth), 
                      religiosity_std = religiosity/sd(religiosity),
                      ethsalience_std = ethsalience/sd(ethsalience), 
                      rcblack_std = rcblack/sd(rcblack),
                      rcwhite_std = rcwhite/sd(rcwhite), 
                      rccol_std = rccol/sd(rccol),
                      EDUC_std = EDUC/sd(EDUC))

# balance between treated and control
balance_table <- trc %>% group_by(TRCKNOW) %>% summarize(
  age_std = mean(age_std),
  female_std = mean(female_std),
  wealth_std = mean(wealth_std),
  religiosity_std = mean(religiosity_std),
  ethsalience_std = mean(ethsalience_std),
  rcblack_std = mean(rcblack_std),
  rcwhite_std = mean(rcwhite_std),
  rccol_std = mean(rccol_std),
  EDUC_std = mean(EDUC_std),
  .groups = "keep")

balance_table

```
The greatest differences in covariates between treatment and control is that the treatment group had more women, higher indicators of wealth (as measured through asset ownership), and higher levels of education than the control group. All other covariates were within 0.1 between the two groups, with the treatment group being slightly younger, less religious, with a higher ethsalience, more black and white respondents, and fewer coloured respondents than the control group.

## Part c

1. Estimating the propensity score for each observation

```{r, echo=TRUE}

pscore_model <- glm(TRCKNOW ~ age + female + wealth + religiosity + 
                      ethsalience + rcblack + rcwhite + rccol + 
                      EDUC, data = trc, family = binomial(link="logit"))

trc$e <- predict(pscore_model, type = "response")

```

2. Constructing inverse propensity of treatment weights

```{r, echo=TRUE}

trc$weight <- NA

trc$weight[trc$TRCKNOW == 1] <- 1/trc$e[trc$TRCKNOW == 1]

trc$weight[trc$TRCKNOW == 0] <- 1/(1 - trc$e[trc$TRCKNOW == 0])

```

3. Constructing an IPW estimator

```{r, echo=TRUE}

point_wtd <- mean(trc$weight * trc$RUSTAND * trc$TRCKNOW -
                    trc$weight * trc$RUSTAND * (1-trc$TRCKNOW))

point_wtd

```

The point estimate of the ATE is: -0.162329

4. Plotting the histograms of the propensity scores in treatment and control

```{r, echo=TRUE}

hist(trc$e[trc$TRCKNOW ==1], xlab = "Propensity Score", 
     main= "Propensity Scores, Red = Treated, Blue = Control",
     xlim = c(0,1), breaks = 20, col = rgb(1,0,0,0.5),)
hist(trc$e[trc$TRCKNOW ==0], xlab = "Propensity Score", 
     main= "Propensity Scores among Control", 
     xlim = c(0,1), breaks = 20, add=T, col= rgb(0,0,1,0.5),)

```

## Part d

```{r, echo=TRUE}

set.seed(10003)
nBoot <- 1000
ate_boot <- rep(NA, nBoot)

for(boot in 1:nBoot){
  # sample with replacement
  trc_boot <- trc[sample(1:nrow(trc), nrow(trc), replace=T),]
  
  # fit propensity score model on sample
  pscore_model_boot <- glm(TRCKNOW ~ age + female + wealth + religiosity + 
                             ethsalience + rcblack + rcwhite + rccol +
                             EDUC, data = trc_boot, 
                           family = binomial(link="logit"))
  
  # get propensity scores
  trc_boot$e <- predict(pscore_model_boot, type = "response")
  
  # get IPTW
  trc_boot$weight <- NA

  trc_boot$weight[trc_boot$TRCKNOW == 1] <- 1/trc_boot$e[trc_boot$TRCKNOW == 1]
  trc_boot$weight[trc_boot$TRCKNOW == 0] <- 1/(1 - trc_boot$e[trc_boot$TRCKNOW == 0])
  
  # find IPW for sample
  ate_boot[boot] <- mean(trc_boot$weight * trc_boot$RUSTAND * trc_boot$TRCKNOW -
                    trc_boot$weight * trc_boot$RUSTAND * (1-trc_boot$TRCKNOW))
}

Std <- sd(ate_boot)

CI_lower <- point_wtd - qnorm(.975)*sd(ate_boot)
CI_upper <- point_wtd + qnorm(.975)*sd(ate_boot)

output <- tibble(Estimate = point_wtd,
                 Std = Std,
                 "95% CI lower" = CI_lower,
                 "95% CI upper" = CI_upper)

output

```
Inverse Propensity Weighting gave us a higher standard error than our difference-in-means estimate (0.0454 > 0.0443). This gave us a wider confidence interval than in part A. Additionally, our estimate of the ATE was larger than in Part A - although still negative (-0.162 > -0.218). Additionally, because zero falls outside of our confidence interval, we can reject the null hypothesis of no treatment effect (as in Part A) and conclude that exposure to the TRC had a significant negative effect on racial attitudes.

# Problem 4

## Part a

```{r, echo=TRUE}

md_match <- Match(Y = trc$RUSTAND, Tr = trc$TRCKNOW, X = trc[c("age", 
                                                               "female", 
                                                               "wealth", 
                                                               "religiosity", 
                                                               "ethsalience", 
                                                               "rcblack", 
                                                               "rcwhite", 
                                                               "rccol", 
                                                               "EDUC")], 
                  estimand = "ATE", Weight = 2)

summary(md_match)

CI_95_match <- c(md_match$est - qnorm(.975)*md_match$se, 
                 md_match$est + qnorm(.975)*md_match$se)
CI_95_match

```
The 95% confidence interval is [-0.2814, -0.0818]. Because this interval doesn't contain 0, our estimate of the ATE is statistically significant.

## Part b

```{r, echo=TRUE}

md_match3 <- Match(Y = trc$RUSTAND, Tr = trc$TRCKNOW, X = trc[c("age", 
                                                                "female", 
                                                                "wealth", 
                                                                "religiosity", 
                                                                "ethsalience", 
                                                                "rcblack", 
                                                                "rcwhite", 
                                                                "rccol", 
                                                                "EDUC")], 
                   estimand = "ATE", M=3, Weight = 2)

summary(md_match3)

CI_95_match3 <- c(md_match3$est - qnorm(.975)*md_match3$se, 
                 md_match3$est + qnorm(.975)*md_match3$se)
CI_95_match3

```
As compared to Part A, the standard error decreased when we matched 3 observations instead of 1 (0.046918 < 0.050924).

## Part c

```{r, echo=TRUE}

md_match_bc <- Match(Y = trc$RUSTAND, Tr = trc$TRCKNOW, X = trc[c("age", 
                                                                  "female", 
                                                                  "wealth", 
                                                                  "religiosity", 
                                                                  "ethsalience", 
                                                                  "rcblack", 
                                                                  "rcwhite", 
                                                                  "rccol", 
                                                                  "EDUC")], 
                     estimand = "ATE", M = 3, BiasAdjust=TRUE, Weight = 2)

summary(md_match_bc)

CI_95_match_bc <- c(md_match_bc$est - qnorm(.975)*md_match_bc$se, 
                 md_match_bc$est + qnorm(.975)*md_match_bc$se)
CI_95_match_bc

```
Compared to Parts A and B, the standard error decreased after adjusting for bias (0.046892 < 0.046918 and 0.046892 < 0.050924).

## Part d

```{r, echo=TRUE}

# For each unique treated index, add up the weights for all of the times it appears as a match
treated_weights <- sapply(unique(md_match_bc$index.treated), function(x)
  sum(md_match_bc$weights[md_match_bc$index.treated == x]))

names(treated_weights) <- unique(md_match_bc$index.treated)

# same for control group
control_weights <- sapply(unique(md_match_bc$index.control), function(x)
  sum(md_match_bc$weights[md_match_bc$index.control == x]))

names(control_weights) <- unique(md_match_bc$index.control)

# putting weights in dataset
trc <- trc %>% mutate(match_weights = 0)
trc$match_weights[as.integer(names(treated_weights))] <- treated_weights
trc$match_weights[as.integer(names(control_weights))] <- control_weights

# standardizing covariates
trc<- trc %>% mutate(age_std = 100*age/sd(age[TRCKNOW==1]),
              female_std = 100*female/sd(female[TRCKNOW==1]),
              wealth_std = 100*wealth/sd(wealth[TRCKNOW==1]),
              religiosity_std = 100*religiosity/sd(religiosity[TRCKNOW==1]),
              ethsalience_std = 100*ethsalience/sd(ethsalience[TRCKNOW==1]),
              rcblack_std = 100*rcblack/sd(rcblack[TRCKNOW==1]),
              rcwhite_std = 100*rcwhite/sd(rcwhite[TRCKNOW==1]),
              rccol_std = 100*rccol/sd(rccol[TRCKNOW==1]),
              EDUC_std = 100*EDUC/sd(EDUC[TRCKNOW==1]))

# creating the balance table with standardized covariates
balance_table_match <- trc %>% group_by(TRCKNOW) %>% summarize(
  age_std = weighted.mean(age_std, match_weights),
  female_std = weighted.mean(female_std, match_weights),
  wealth_std = weighted.mean(wealth_std, match_weights),
  religiosity_std = weighted.mean(religiosity_std, match_weights),
  ethsalience_std = weighted.mean(ethsalience_std, match_weights),
  rcblack_std =weighted.mean(rcblack_std, match_weights),
  rcwhite_std = weighted.mean(rcwhite_std, match_weights),
  rccol_std = weighted.mean(rccol_std, match_weights),
  EDUC_std = weighted.mean(EDUC_std, match_weights),
  .groups="keep") 

balance_table_match

```